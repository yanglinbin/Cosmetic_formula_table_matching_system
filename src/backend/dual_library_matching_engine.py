#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒé…æ–¹åº“åŒ¹é…å¼•æ“
æ”¯æŒé…æ–¹åº“ä¸å¾…åŒ¹é…é…æ–¹åº“ä¹‹é—´çš„æ™ºèƒ½åŒ¹é…
å®ç°åŸºäºæ›´æ–°éœ€æ±‚çš„ä¸¤æ®µå¼ç›¸ä¼¼åº¦è®¡ç®—ç®—æ³•
"""

import numpy as np
from typing import Dict, List, Optional
from dataclasses import dataclass
import logging
from sklearn.metrics.pairwise import cosine_similarity
from collections import defaultdict

from src.backend.sql.mysql_models import (
    Formulas, FormulasToBeMatched,
    DualFormulaLibraryHandler, SystemConfigManager
)
from sqlalchemy import or_

logger = logging.getLogger(__name__)


@dataclass
class DualLibraryMatchingParameters:
    """åŒé…æ–¹åº“åŒ¹é…ç®—æ³•å‚æ•°"""
    # ç±»åˆ«æƒé‡
    category_weights: Dict[str, float]

    # é…æ–™ç»„æˆvsé…æ–™æ¯”ä¾‹æƒé‡
    composition_weight: float
    proportion_weight: float

    # å¤é…ç›¸ä¼¼åº¦å‚æ•°
    compound_threshold: float

    # å…¶ä»–å‚æ•°
    min_similarity_threshold: float
    max_results: int


@dataclass
class DualLibraryMatchResult:
    """åŒé…æ–¹åº“åŒ¹é…ç»“æœ"""
    source_formula_id: int
    source_formula_name: str
    target_formula_id: int
    target_formula_name: str
    similarity_score: float
    composition_similarity: float
    proportion_similarity: float
    category_similarities: Dict[str, float]
    common_ingredients: List[str]
    common_ingredients_count: int
    total_ingredients_count: int
    match_details: Dict


class DualLibraryMatchingEngine:
    """åŒé…æ–¹åº“åŒ¹é…å¼•æ“"""

    def __init__(self, parameters: DualLibraryMatchingParameters = None):
        """åˆå§‹åŒ–åŒ¹é…å¼•æ“"""
        self.parameters = parameters or self._get_default_parameters()

        # æˆåˆ†åˆ†ç±»ç¼“å­˜
        self._ingredient_categories = {}

        # å¤é…ä½“ç³»ç¼“å­˜
        self._compound_systems = {}

    def _get_default_parameters(self) -> DualLibraryMatchingParameters:
        """è·å–é»˜è®¤åŒ¹é…å‚æ•°ï¼ˆç¡¬ç¼–ç å¤‡ç”¨ï¼‰"""
        return DualLibraryMatchingParameters(
            category_weights={
                "é˜²è…å‰‚": 0.35,
                "ä¹³åŒ–å‰‚": 0.15,
                "å¢ç¨ å‰‚": 0.15,
                "æŠ—æ°§åŒ–å‰‚": 0.1,
                "è¡¨é¢æ´»æ€§å‰‚": 0.1,
                "å…¶ä»–": 0.15
            },
            composition_weight=0.8,
            proportion_weight=0.2,
            compound_threshold=0.6,
            min_similarity_threshold=0.0,
            max_results=5
        )

    def _load_parameters_from_db(self, session) -> DualLibraryMatchingParameters:
        """ä»æ•°æ®åº“åŠ è½½åŒ¹é…å‚æ•°"""
        try:
            # è·å–åˆ†ç±»æƒé‡
            category_weights = SystemConfigManager.get_category_weights(session)

            # è·å–åŒ¹é…ç®—æ³•å‚æ•°
            matching_params = SystemConfigManager.get_matching_parameters(session)

            logger.info(f"ä»æ•°æ®åº“åŠ è½½é…ç½®æˆåŠŸ - åˆ†ç±»æƒé‡: {category_weights}")
            logger.info(f"ä»æ•°æ®åº“åŠ è½½é…ç½®æˆåŠŸ - åŒ¹é…å‚æ•°: {matching_params}")

            return DualLibraryMatchingParameters(
                category_weights=category_weights,
                composition_weight=matching_params['composition_weight'],
                proportion_weight=matching_params['proportion_weight'],
                compound_threshold=matching_params['compound_threshold'],
                min_similarity_threshold=matching_params['min_similarity_threshold'],
                max_results=5  # è¿™ä¸ªå‚æ•°å¯ä»¥åç»­ä¹ŸåŠ å…¥é…ç½®
            )

        except Exception as e:
            logger.warning(f"ä»æ•°æ®åº“åŠ è½½é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            return self._get_default_parameters()

    def match_formula_against_library(
            self,
            source_formula_id: int,
            session,
            target_formulas: List[int] = None,
            strict_mode: bool = False
    ) -> List[DualLibraryMatchResult]:
        """
        å°†å¾…åŒ¹é…é…æ–¹ä¸é…æ–¹åº“è¿›è¡ŒåŒ¹é…
        
        Args:
            source_formula_id: å¾…åŒ¹é…é…æ–¹ID (formulas_to_be_matchedè¡¨)
            session: æ•°æ®åº“ä¼šè¯
            target_formulas: ç›®æ ‡é…æ–¹IDåˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™åŒ¹é…æ‰€æœ‰é…æ–¹åº“é…æ–¹
            
        Returns:
            åŒ¹é…ç»“æœåˆ—è¡¨ï¼ŒæŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—
        """
        try:
            # ä»æ•°æ®åº“åŠ è½½æœ€æ–°é…ç½®
            self.parameters = self._load_parameters_from_db(session)

            # è·å–å¾…åŒ¹é…é…æ–¹
            source_formula = session.query(FormulasToBeMatched).filter(
                FormulasToBeMatched.id == source_formula_id
            ).first()

            if not source_formula:
                raise ValueError(f"å¾…åŒ¹é…é…æ–¹ {source_formula_id} ä¸å­˜åœ¨")

            # è·å–å¾…åŒ¹é…é…æ–¹ç»“æ„
            source_structure = DualFormulaLibraryHandler.get_formula_structure(
                source_formula_id, session, 'to_be_matched'
            )

            # è·å–ç›®æ ‡é…æ–¹åˆ—è¡¨
            if target_formulas is None:
                if strict_mode:
                    # ä¸¥æ ¼èŒƒå›´åŒ¹é…ï¼šåªåŒ¹é…ç›¸åŒäº§å“ç±»å‹å’Œå®¢æˆ·çš„é…æ–¹
                    logger.info(f"ä¸¥æ ¼æ¨¡å¼åŒ¹é…ï¼šäº§å“ç±»å‹={source_formula.product_type}, å®¢æˆ·={source_formula.customer}")

                    # è§£ææºé…æ–¹çš„äº§å“ç±»å‹
                    source_product_type = source_formula.product_type or ""
                    source_customer = source_formula.customer or ""

                    # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                    query = session.query(Formulas)

                    # äº§å“ç±»å‹è¿‡æ»¤
                    if source_product_type:
                        # å¦‚æœæ˜¯æ–°æ ¼å¼ï¼ˆå¤§ç±»-ç»†åˆ†ç±»å‹ï¼‰ï¼Œç²¾ç¡®åŒ¹é…
                        # å¦‚æœæ˜¯æ—§æ ¼å¼ï¼ˆåªæœ‰å¤§ç±»ï¼‰ï¼ŒåŒ¹é…æ‰€æœ‰ç›¸åŒå¤§ç±»çš„é…æ–¹
                        if '-' in source_product_type:
                            # ç²¾ç¡®åŒ¹é…æ–°æ ¼å¼
                            query = query.filter(Formulas.product_type == source_product_type)
                        else:
                            # åŒ¹é…ç›¸åŒå¤§ç±»çš„æ‰€æœ‰é…æ–¹ï¼ˆå…¼å®¹æ–°æ—§æ ¼å¼ï¼‰
                            query = query.filter(
                                or_(
                                    Formulas.product_type == source_product_type,  # æ—§æ ¼å¼ç²¾ç¡®åŒ¹é…
                                    Formulas.product_type.like(f"{source_product_type}-%")  # æ–°æ ¼å¼å¤§ç±»åŒ¹é…
                                )
                            )

                    # å®¢æˆ·è¿‡æ»¤
                    if source_customer:
                        query = query.filter(Formulas.customer == source_customer)
                    else:
                        # å¦‚æœæºé…æ–¹æ²¡æœ‰å®¢æˆ·ä¿¡æ¯ï¼ŒåªåŒ¹é…åŒæ ·æ²¡æœ‰å®¢æˆ·ä¿¡æ¯çš„é…æ–¹
                        query = query.filter(or_(Formulas.customer == "", Formulas.customer.is_(None)))

                    target_formulas_query = query.all()
                    logger.info(f"ä¸¥æ ¼æ¨¡å¼è¿‡æ»¤åæ‰¾åˆ° {len(target_formulas_query)} ä¸ªå€™é€‰é…æ–¹")
                else:
                    # å¸¸è§„æ¨¡å¼ï¼šåŒ¹é…æ‰€æœ‰é…æ–¹
                    target_formulas_query = session.query(Formulas).all()
                    logger.info(f"å¸¸è§„æ¨¡å¼åŒ¹é…æ‰€æœ‰ {len(target_formulas_query)} ä¸ªé…æ–¹")

                target_formula_ids = [f.id for f in target_formulas_query]
            else:
                target_formula_ids = target_formulas

            # æ‰§è¡Œæ‰¹é‡åŒ¹é…
            match_results = []
            for target_formula_id in target_formula_ids:
                try:
                    result = self._match_single_pair(
                        source_formula, source_structure,
                        target_formula_id, session
                    )

                    if result and result.similarity_score >= self.parameters.min_similarity_threshold:
                        match_results.append(result)

                except Exception as e:
                    logger.warning(f"åŒ¹é…é…æ–¹ {target_formula_id} æ—¶å‡ºé”™: {e}")
                    continue

            # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶è¿”å›å‰Nä¸ªç»“æœ
            match_results.sort(key=lambda x: x.similarity_score, reverse=True)
            return match_results[:self.parameters.max_results]

        except Exception as e:
            logger.error(f"é…æ–¹åŒ¹é…å¤±è´¥: {e}")
            raise e

    def _match_single_pair(
            self,
            source_formula: FormulasToBeMatched,
            source_structure: Dict,
            target_formula_id: int,
            session
    ) -> Optional[DualLibraryMatchResult]:
        """åŒ¹é…å•ä¸ªé…æ–¹å¯¹"""
        try:
            # è·å–ç›®æ ‡é…æ–¹
            target_formula = session.query(Formulas).filter(
                Formulas.id == target_formula_id
            ).first()

            if not target_formula:
                return None

            # è·å–ç›®æ ‡é…æ–¹ç»“æ„
            target_structure = DualFormulaLibraryHandler.get_formula_structure(
                target_formula_id, session, 'reference'
            )

            # è®¡ç®—æˆåˆ†ç»„æˆç›¸ä¼¼åº¦ï¼ˆç¬¬ä¸€æ®µï¼‰
            composition_similarity = self._calculate_composition_similarity(
                source_structure, target_structure, session
            )

            # è®¡ç®—æˆåˆ†æ¯”ä¾‹ç›¸ä¼¼åº¦ï¼ˆç¬¬äºŒæ®µï¼‰
            proportion_similarity = self._calculate_proportion_similarity(
                source_structure, target_structure
            )

            # è®¡ç®—åˆ†ç±»ç›¸ä¼¼åº¦
            category_similarities = self._calculate_category_similarities(
                source_structure, target_structure, session
            )

            # è®¡ç®—æ€»ç›¸ä¼¼åº¦
            total_similarity = (
                    self.parameters.composition_weight * composition_similarity +
                    self.parameters.proportion_weight * proportion_similarity
            )

            # ç²¾åº¦ä¿®æ­£ï¼šé¿å…æµ®ç‚¹æ•°è¯¯å·®
            if abs(total_similarity - 1.0) < 1e-10:
                total_similarity = 1.0
            elif abs(total_similarity) < 1e-10:
                total_similarity = 0.0

            # è·å–å…±åŒæˆåˆ†ä¿¡æ¯
            common_ingredients = self._get_common_ingredients(
                source_structure, target_structure
            )

            # æ„å»ºåŒ¹é…è¯¦æƒ…
            source_ingredients_list = self._extract_ingredients_list(source_structure)
            target_ingredients_list = self._extract_ingredients_list(target_structure)

            match_details = {
                "source_ingredients_count": len(source_ingredients_list),
                "target_ingredients_count": len(target_ingredients_list),
                "composition_method": "weighted_jaccard",
                "proportion_method": "weighted_cosine",
                "algorithm_version": "dual_library_v1.0",
                "parameters": {
                    "composition_weight": self.parameters.composition_weight,
                    "proportion_weight": self.parameters.proportion_weight,
                    "category_weights": self.parameters.category_weights
                }
            }

            # åˆ›å»ºåŒ¹é…ç»“æœ
            result = DualLibraryMatchResult(
                source_formula_id=source_formula.id,
                source_formula_name=source_formula.formula_name,
                target_formula_id=target_formula.id,
                target_formula_name=target_formula.formula_name,
                similarity_score=total_similarity,
                composition_similarity=composition_similarity,
                proportion_similarity=proportion_similarity,
                category_similarities=category_similarities,
                common_ingredients=common_ingredients,
                common_ingredients_count=len(common_ingredients),
                total_ingredients_count=len(set([ing['chinese_name'] for ing in source_ingredients_list])),
                match_details=match_details
            )

            return result

        except Exception as e:
            logger.error(f"å•ä¸ªé…æ–¹åŒ¹é…å¤±è´¥: {e}")
            return None

    def _calculate_composition_similarity(
            self,
            source_structure: Dict,
            target_structure: Dict,
            session
    ) -> float:
        """è®¡ç®—æˆåˆ†ç»„æˆç›¸ä¼¼åº¦ï¼ˆä»…ä½¿ç”¨åŠ æƒJaccardï¼‰"""
        try:
            # æ ¹æ®è¦æ±‚ï¼Œç»„æˆç›¸ä¼¼åº¦åªä½¿ç”¨åŠ æƒJaccard
            weighted_jaccard = self._calculate_weighted_jaccard_by_category(
                source_structure, target_structure, session
            )

            logger.info(f"ğŸ” ç»„æˆç›¸ä¼¼åº¦è®¡ç®—ç»“æœ:")
            logger.info(f"  åŠ æƒJaccard: {weighted_jaccard:.4f}")
            logger.info(f"  æœ€ç»ˆç»„æˆç›¸ä¼¼åº¦: {weighted_jaccard:.4f} (ä»…ä½¿ç”¨åŠ æƒJaccard)")

            return weighted_jaccard

        except Exception as e:
            logger.error(f"è®¡ç®—æˆåˆ†ç»„æˆç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return 0.0

    def _calculate_proportion_similarity(
            self,
            source_structure: Dict,
            target_structure: Dict
    ) -> float:
        """è®¡ç®—æˆåˆ†æ¯”ä¾‹ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨å¹¶é›†è¿›è¡ŒåŠ æƒä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ï¼‰"""
        try:
            # ä½¿ç”¨æå–æˆåˆ†åˆ—è¡¨æ–¹æ³•ï¼Œä¿æŒå¤é…æ•´ä½“æ€§
            source_ingredients_list = self._extract_ingredients_list(source_structure)
            target_ingredients_list = self._extract_ingredients_list(target_structure)

            # æ„å»ºæˆåˆ†æ¯”ä¾‹å­—å…¸
            source_proportions = {}
            target_proportions = {}

            # å¤„ç†æºé…æ–¹æ¯”ä¾‹ï¼ˆå¤é…ä½œä¸ºæ•´ä½“ï¼‰
            for ing in source_ingredients_list:
                name = ing['chinese_name']
                content = ing.get('content', 0)
                source_proportions[name] = content

            # å¤„ç†ç›®æ ‡é…æ–¹æ¯”ä¾‹ï¼ˆå¤é…ä½œä¸ºæ•´ä½“ï¼‰
            for ing in target_ingredients_list:
                name = ing['chinese_name']
                content = ing.get('content', 0)
                target_proportions[name] = content

            # æ„å»ºå¹¶é›†çš„æ‰€æœ‰æˆåˆ†åˆ—è¡¨
            all_ingredients = sorted(list(set(source_proportions.keys()) | set(target_proportions.keys())))

            if len(all_ingredients) == 0:
                return 0.0

            # æ„å»ºæ¯”ä¾‹å‘é‡ï¼ˆåŸºäºå¹¶é›†ï¼‰
            source_vector = []
            target_vector = []

            for ingredient in all_ingredients:
                source_vector.append(source_proportions.get(ingredient, 0))
                target_vector.append(target_proportions.get(ingredient, 0))

            # è®¡ç®—åŠ æƒä½™å¼¦ç›¸ä¼¼åº¦
            if np.sum(source_vector) == 0 or np.sum(target_vector) == 0:
                return 0.0

            source_array = np.array(source_vector).reshape(1, -1)
            target_array = np.array(target_vector).reshape(1, -1)

            cosine_sim = cosine_similarity(source_array, target_array)[0, 0]

            # è®°å½•ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ç»“æœ
            logger.info(f"ğŸ“Š æ¯”ä¾‹ç›¸ä¼¼åº¦è®¡ç®—ç»“æœ:")
            logger.info(f"  æˆåˆ†å¹¶é›†æ•°é‡: {len(all_ingredients)}")
            logger.info(f"  æºé…æ–¹å‘é‡: {source_vector[:5]}...({len(source_vector)} ä¸ªæˆåˆ†)" if len(source_vector) > 5 else f"  æºé…æ–¹å‘é‡: {source_vector}")
            logger.info(f"  ç›®æ ‡é…æ–¹å‘é‡: {target_vector[:5]}...({len(target_vector)} ä¸ªæˆåˆ†)" if len(target_vector) > 5 else f"  ç›®æ ‡é…æ–¹å‘é‡: {target_vector}")
            logger.info(f"  ä½™å¼¦ç›¸ä¼¼åº¦åŸå§‹å€¼: {cosine_sim:.6f}")

            # ç²¾åº¦ä¿®æ­£ï¼šé¿å…æµ®ç‚¹æ•°è¯¯å·®
            if not np.isnan(cosine_sim):
                # å¦‚æœéå¸¸æ¥è¿‘1.0ï¼Œåˆ™è®¤ä¸ºæ˜¯å®Œå…¨ç›¸åŒ
                if abs(cosine_sim - 1.0) < 1e-10:
                    cosine_sim = 1.0
                    logger.info(f"  ä½™å¼¦ç›¸ä¼¼åº¦ä¿®æ­£ä¸º: {cosine_sim:.6f} (æ¥è¿‘1.0)")
                # å¦‚æœéå¸¸æ¥è¿‘0.0ï¼Œåˆ™è®¤ä¸ºæ˜¯å®Œå…¨ä¸åŒ
                elif abs(cosine_sim) < 1e-10:
                    cosine_sim = 0.0
                    logger.info(f"  ä½™å¼¦ç›¸ä¼¼åº¦ä¿®æ­£ä¸º: {cosine_sim:.6f} (æ¥è¿‘0.0)")
                else:
                    logger.info(f"  ä½™å¼¦ç›¸ä¼¼åº¦æœ€ç»ˆå€¼: {cosine_sim:.6f}")
                return float(cosine_sim)
            else:
                logger.warning(f"  ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ç»“æœä¸ºNaNï¼Œè¿”å›0.0")
                return 0.0

        except Exception as e:
            logger.error(f"è®¡ç®—æˆåˆ†æ¯”ä¾‹ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return 0.0

    def _calculate_weighted_jaccard_by_category(
            self,
            source_structure: Dict,
            target_structure: Dict,
            session
    ) -> float:
        """æŒ‰åˆ†ç±»è®¡ç®—åŠ æƒJaccardç›¸ä¼¼åº¦"""
        try:
            logger.info(f"ğŸ” å¼€å§‹è®¡ç®—åŠ æƒJaccardç›¸ä¼¼åº¦...")

            # æŒ‰åˆ†ç±»åˆ†ç»„æˆåˆ† - å±•å¼€æˆåˆ†åˆ—è¡¨
            source_ingredients_list = self._extract_ingredients_list(source_structure)
            target_ingredients_list = self._extract_ingredients_list(target_structure)

            logger.info(f"  æºé…æ–¹æˆåˆ†æ€»æ•°: {len(source_ingredients_list)}")
            logger.info(f"  ç›®æ ‡é…æ–¹æˆåˆ†æ€»æ•°: {len(target_ingredients_list)}")

            source_by_category = self._group_ingredients_by_category(
                source_ingredients_list, session
            )
            target_by_category = self._group_ingredients_by_category(
                target_ingredients_list, session
            )

            logger.info(f"  æºé…æ–¹åˆ†ç±»: {list(source_by_category.keys())}")
            logger.info(f"  ç›®æ ‡é…æ–¹åˆ†ç±»: {list(target_by_category.keys())}")

            # è¯¦ç»†æ˜¾ç¤ºå„åˆ†ç±»çš„æˆåˆ†ï¼ˆæ˜¾ç¤ºæ•°é‡ï¼Œæ ‡è¯†ç¬¦åˆ—è¡¨åœ¨debugæ¨¡å¼ä¸‹æ˜¾ç¤ºï¼‰
            for category, ingredients in source_by_category.items():
                logger.info(f"    æºé…æ–¹-{category}: {len(ingredients)}ä¸ªæˆåˆ†")
                logger.debug(f"      æ ‡è¯†ç¬¦åˆ—è¡¨: {ingredients}")
            for category, ingredients in target_by_category.items():
                logger.info(f"    ç›®æ ‡é…æ–¹-{category}: {len(ingredients)}ä¸ªæˆåˆ†")
                logger.debug(f"      æ ‡è¯†ç¬¦åˆ—è¡¨: {ingredients}")

            # è®¡ç®—å„åˆ†ç±»çš„Jaccardç›¸ä¼¼åº¦
            category_similarities = {}
            all_categories = set(source_by_category.keys()) | set(target_by_category.keys())

            logger.info(f"  å‚ä¸è®¡ç®—çš„åˆ†ç±»: {sorted(all_categories)}")

            for category in all_categories:
                source_set = set(source_by_category.get(category, []))
                target_set = set(target_by_category.get(category, []))

                intersection = len(source_set & target_set)
                union = len(source_set | target_set)

                if union > 0:
                    category_similarities[category] = intersection / union
                else:
                    category_similarities[category] = 0.0

                logger.info(
                    f"  åˆ†ç±» '{category}': äº¤é›†={intersection}, å¹¶é›†={union}, ç›¸ä¼¼åº¦={category_similarities[category]:.4f}")
                if intersection > 0:
                    logger.debug(f"    å…±åŒæ ‡è¯†ç¬¦: {sorted(source_set & target_set)}")
                if len(source_set - target_set) > 0:
                    logger.debug(f"    æºç‹¬æœ‰æ ‡è¯†ç¬¦: {sorted(source_set - target_set)}")
                if len(target_set - source_set) > 0:
                    logger.debug(f"    ç›®æ ‡ç‹¬æœ‰æ ‡è¯†ç¬¦: {sorted(target_set - source_set)}")

            # åŠ æƒå¹³å‡ - åªå¯¹å®é™…å­˜åœ¨æˆåˆ†çš„åˆ†ç±»è¿›è¡Œè®¡ç®—
            logger.info(f"  å¼€å§‹è®¡ç®—åŠ æƒå¹³å‡...")
            weighted_similarity = 0.0
            total_weight = 0.0

            # æ‰¾å‡ºå®é™…æœ‰æˆåˆ†çš„åˆ†ç±»ï¼ˆæºé…æ–¹æˆ–ç›®æ ‡é…æ–¹ä¸­è‡³å°‘æœ‰ä¸€ä¸ªæœ‰è¯¥åˆ†ç±»ï¼‰
            active_categories = set()
            for category in all_categories:
                source_set = set(source_by_category.get(category, []))
                target_set = set(target_by_category.get(category, []))
                # åªæœ‰å½“æºé…æ–¹æˆ–ç›®æ ‡é…æ–¹ä¸­è‡³å°‘æœ‰ä¸€ä¸ªé…æ–¹åŒ…å«è¯¥åˆ†ç±»æ—¶ï¼Œæ‰å‚ä¸è®¡ç®—
                if len(source_set) > 0 or len(target_set) > 0:
                    active_categories.add(category)

            logger.info(f"  æœ‰æ•ˆåˆ†ç±»ï¼ˆæœ‰æˆåˆ†çš„åˆ†ç±»ï¼‰: {sorted(active_categories)}")

            # åªå¯¹æœ‰æ•ˆåˆ†ç±»è¿›è¡Œæƒé‡è®¡ç®—
            for category in active_categories:
                if category in category_similarities:
                    similarity = category_similarities[category]
                    weight = self.parameters.category_weights.get(category,
                                                                  self.parameters.category_weights.get("å…¶ä»–", 0.15))
                    contribution = weight * similarity
                    weighted_similarity += contribution
                    total_weight += weight

                    logger.info(
                        f"    åˆ†ç±» '{category}': ç›¸ä¼¼åº¦={similarity:.4f}, æƒé‡={weight:.2f}, è´¡çŒ®={contribution:.4f}")

            # æ˜¾ç¤ºè¢«è·³è¿‡çš„ç©ºåˆ†ç±»
            skipped_categories = set(self.parameters.category_weights.keys()) - active_categories
            if skipped_categories:
                logger.info(f"  è·³è¿‡çš„ç©ºåˆ†ç±»: {sorted(skipped_categories)}")

            final_weighted = weighted_similarity / total_weight if total_weight > 0 else 0.0
            logger.info(f"  å‚ä¸è®¡ç®—çš„æ€»æƒé‡: {total_weight:.2f}")
            logger.info(f"  åŠ æƒæ€»åˆ†: {weighted_similarity:.4f}")
            logger.info(f"  æœ€ç»ˆåŠ æƒJaccard: {final_weighted:.4f}")

            return final_weighted

        except Exception as e:
            logger.error(f"è®¡ç®—åŠ æƒJaccardç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return 0.0

    def _calculate_compound_similarity(self, source_compound: Dict, target_compound: Dict) -> float:
        """è®¡ç®—å¤é…æˆåˆ†ç›¸ä¼¼åº¦ï¼ˆåŸºäºcatalog_idçš„Jaccardç®—æ³•ï¼‰"""
        try:
            if source_compound.get('type') != 'compound' or target_compound.get('type') != 'compound':
                return 0.0

            # è·å–å¤é…ä¸­æˆåˆ†çš„catalog_idé›†åˆï¼Œç¡®ä¿åŒ¹é…ä¸€è‡´æ€§
            source_catalog_ids = set()
            target_catalog_ids = set()

            # ä»components_detailä¸­æå–catalog_id
            source_components = source_compound.get('components_detail', [])
            target_components = target_compound.get('components_detail', [])

            for comp in source_components:
                catalog_id = comp.get('catalog_id')
                if catalog_id:
                    source_catalog_ids.add(catalog_id)
                else:
                    logger.warning(f"å¤é…å­æˆåˆ†ç¼ºå°‘catalog_id: {comp.get('chinese_name', 'æœªçŸ¥')}")

            for comp in target_components:
                catalog_id = comp.get('catalog_id')
                if catalog_id:
                    target_catalog_ids.add(catalog_id)
                else:
                    logger.warning(f"å¤é…å­æˆåˆ†ç¼ºå°‘catalog_id: {comp.get('chinese_name', 'æœªçŸ¥')}")

            if not source_catalog_ids or not target_catalog_ids:
                return 0.0

            # è®¡ç®—åŸºäºcatalog_idçš„Jaccardç›¸ä¼¼åº¦
            intersection = len(source_catalog_ids & target_catalog_ids)
            union = len(source_catalog_ids | target_catalog_ids)
            compound_similarity = intersection / union if union > 0 else 0.0

            logger.info(f"ğŸ” å¤é…ç›¸ä¼¼åº¦: {compound_similarity:.4f} (äº¤é›†:{intersection}, å¹¶é›†:{union})")
            logger.info(f"  æºå¤é…catalog_ids: {sorted(source_catalog_ids)}")
            logger.info(f"  ç›®æ ‡å¤é…catalog_ids: {sorted(target_catalog_ids)}")

            return compound_similarity

        except Exception as e:
            logger.error(f"è®¡ç®—å¤é…ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return 0.0

    def _is_compound_match_success(self, similarity: float) -> bool:
        """åˆ¤æ–­å¤é…æ˜¯å¦åŒ¹é…æˆåŠŸï¼ˆç›¸ä¼¼åº¦>60%ï¼‰"""
        return similarity >= self.parameters.compound_threshold

    def _calculate_category_similarities(
            self,
            source_structure: Dict,
            target_structure: Dict,
            session
    ) -> Dict[str, float]:
        """è®¡ç®—å„åˆ†ç±»çš„ç›¸ä¼¼åº¦"""
        try:
            # å±•å¼€æˆåˆ†åˆ—è¡¨
            source_ingredients_list = self._extract_ingredients_list(source_structure)
            target_ingredients_list = self._extract_ingredients_list(target_structure)

            source_by_category = self._group_ingredients_by_category(
                source_ingredients_list, session
            )
            target_by_category = self._group_ingredients_by_category(
                target_ingredients_list, session
            )

            similarities = {}
            all_categories = set(source_by_category.keys()) | set(target_by_category.keys())

            for category in all_categories:
                source_set = set(source_by_category.get(category, []))
                target_set = set(target_by_category.get(category, []))

                intersection = len(source_set & target_set)
                union = len(source_set | target_set)

                similarities[category] = intersection / union if union > 0 else 0.0

            return similarities

        except Exception as e:
            logger.error(f"è®¡ç®—åˆ†ç±»ç›¸ä¼¼åº¦å¤±è´¥: {e}")
            return {}

    def _extract_ingredients_list(self, structure: Dict) -> List[Dict]:
        """ä»é…æ–¹ç»“æ„ä¸­æå–æˆåˆ†åˆ—è¡¨ - å¤é…ä½œä¸ºæ•´ä½“å¤„ç†"""
        ingredients_list = []
        table_type = structure.get('table_type', 'reference')  # è·å–è¡¨ç±»å‹

        for ing in structure.get('ingredients', []):
            if ing.get('type') == 'single':
                # å•é…æˆåˆ† - ç»Ÿä¸€ä½¿ç”¨ingredient_contentå­—æ®µ
                content_value = ing.get('content', 0)
                if content_value == 0:
                    # å¦‚æœcontentä¸º0ï¼Œå°è¯•ä½¿ç”¨actual_content
                    content_value = ing.get('actual_content', 0)

                ingredients_list.append({
                    'type': 'single',
                    'chinese_name': ing['chinese_name'],
                    'inci_name': ing.get('inci_name', ''),
                    'content': content_value,
                    'ingredient_id': ing.get('ingredient_id'),
                    'table_type': table_type,
                    'purpose': ing.get('purpose', 'å…¶ä»–'),  # æ·»åŠ purposeå­—æ®µ
                    'catalog_id': ing.get('catalog_id')  # æ·»åŠ catalog_idç”¨äºåŒ¹é…
                })
            elif ing.get('type') == 'compound':
                # å¤é…æˆåˆ†ä½œä¸ºæ•´ä½“
                components = ing.get('components', [])
                if components:
                    # åˆ›å»ºå¤é…æ•´ä½“æ ‡è¯† - åŸºäºæˆåˆ†ç»„åˆè€Œéingredient_id
                    # ä½¿ç”¨æˆåˆ†çš„ä¸­æ–‡åç§°æ’åºåç”Ÿæˆå”¯ä¸€æ ‡è¯†
                    component_names = sorted([comp.get('chinese_name', '') for comp in components])
                    # å–å‰3ä¸ªä¸»è¦æˆåˆ†ä½œä¸ºæ ‡è¯†ï¼ˆé¿å…åç§°è¿‡é•¿ï¼‰
                    main_identifiers = component_names[:3]
                    compound_identifier = '_'.join(main_identifiers)
                    # ç”Ÿæˆç®€åŒ–çš„å“ˆå¸Œå€¼é¿å…åç§°è¿‡é•¿
                    import hashlib
                    compound_hash = hashlib.md5(compound_identifier.encode('utf-8')).hexdigest()[:8]
                    compound_name = f"å¤é…_{compound_hash}"

                    # è°ƒè¯•ä¿¡æ¯ï¼šè®°å½•å¤é…åç§°ç”Ÿæˆ
                    logger.info(f"ğŸ” å¤é…åç§°ç”Ÿæˆ: {compound_name} <- æˆåˆ†: {main_identifiers}")

                    # è·å–å¤é…ä¸­æ‰€æœ‰æˆåˆ†çš„catalog_idåˆ—è¡¨ï¼ˆç”¨äºåŒ¹é…ï¼‰
                    component_catalog_ids = []
                    for comp in components:
                        catalog_id = comp.get('catalog_id')
                        if catalog_id:
                            component_catalog_ids.append(catalog_id)

                    # æ’åºç¡®ä¿ä¸€è‡´æ€§
                    component_catalog_ids.sort()

                    ingredients_list.append({
                        'type': 'compound',
                        'chinese_name': compound_name,
                        'compound_id': ing.get('ingredient_id'),
                        'ingredient_id': ing.get('ingredient_id'),
                        'total_content': ing.get('total_content', 0),
                        'component_catalog_ids': component_catalog_ids,  # ç”¨äºåŒ¹é…çš„catalog_idåˆ—è¡¨
                        'components_detail': components,
                        'content': ing.get('total_content', 0),
                        'table_type': table_type,
                        'purpose': ing.get('purpose', 'å…¶ä»–')  # æ·»åŠ å¤é…æ•´ä½“çš„purposeå­—æ®µ
                    })
            else:
                # å…¼å®¹æ—§æ ¼å¼
                if 'chinese_name' in ing:
                    ingredients_list.append({
                        'type': 'single',
                        'chinese_name': ing['chinese_name'],
                        'inci_name': ing.get('inci_name', ''),
                        'content': ing.get('actual_content', ing.get('content', 0)),
                        'ingredient_id': ing.get('ingredient_id'),
                        'table_type': table_type
                    })

        return ingredients_list

    def _map_purpose_to_standard_category(self, purpose: str) -> str:
        """å°†åŸå§‹purposeæ˜ å°„åˆ°æ ‡å‡†åˆ†ç±»"""
        if not purpose or not purpose.strip():
            return "å…¶ä»–"

        purpose = purpose.strip().lower()

        # é˜²è…å‰‚å…³é”®è¯
        if any(keyword in purpose for keyword in ['é˜²è…', 'æ€èŒ', 'æŠ—èŒ', 'é˜²éœ‰', 'æŠ‘èŒ', 'æ¶ˆæ¯’']):
            return "é˜²è…å‰‚"

        # ä¹³åŒ–å‰‚å…³é”®è¯
        if any(keyword in purpose for keyword in ['ä¹³åŒ–', 'ç¨³å®š', 'åˆ†æ•£', 'å‡è´¨']):
            return "ä¹³åŒ–å‰‚"

        # å¢ç¨ å‰‚å…³é”®è¯
        if any(keyword in purpose for keyword in ['å¢ç¨ ', 'ç¨ åŒ–', 'èƒ¶å‡', 'ç²˜ç¨ ', 'å‡èƒ¶', 'å¢ç²˜']):
            return "å¢ç¨ å‰‚"

        # æŠ—æ°§åŒ–å‰‚å…³é”®è¯
        if any(keyword in purpose for keyword in ['æŠ—æ°§åŒ–', 'é˜²æ°§åŒ–', 'è¿˜åŸ', 'æ¸…é™¤è‡ªç”±åŸº']):
            return "æŠ—æ°§åŒ–å‰‚"

        # è¡¨é¢æ´»æ€§å‰‚å…³é”®è¯
        if any(keyword in purpose for keyword in ['è¡¨é¢æ´»æ€§', 'æ¸…æ´', 'èµ·æ³¡', 'å»æ±¡', 'æ´—æ¶¤', 'å‘æ³¡', 'æ¶¦æ¹¿']):
            return "è¡¨é¢æ´»æ€§å‰‚"

        # å…¶ä»–å¸¸è§åŠŸèƒ½ä¹Ÿå½’ç±»åˆ°"å…¶ä»–"
        return "å…¶ä»–"

    def _group_ingredients_by_category(self, ingredients: List[Dict], session) -> Dict[str, List]:
        """æŒ‰åˆ†ç±»åˆ†ç»„æˆåˆ† - æ˜ å°„åˆ°æ ‡å‡†6åˆ†ç±»ï¼Œç»Ÿä¸€ä½¿ç”¨å­—ç¬¦ä¸²æ ‡è¯†ç¬¦"""
        try:
            grouped = defaultdict(list)

            for ingredient in ingredients:
                ingredient_type = ingredient.get('type', 'single')
                raw_purpose = ingredient.get('purpose', '')

                # æ˜ å°„åˆ°æ ‡å‡†åˆ†ç±»
                standard_category = self._map_purpose_to_standard_category(raw_purpose)

                if ingredient_type == 'single':
                    # å•é…æˆåˆ†ï¼šå°†catalog_idè½¬æ¢ä¸ºå­—ç¬¦ä¸²ä½œä¸ºåŒ¹é…æ ‡è¯†ç¬¦
                    catalog_id = ingredient.get('catalog_id')
                    if catalog_id:
                        # ä½¿ç”¨å‰ç¼€åŒºåˆ†catalog_idå’Œå¤é…åç§°ï¼Œä¿æŒç±»å‹ä¸€è‡´æ€§
                        grouped[standard_category].append(f"catalog_{catalog_id}")
                    else:
                        # å¦‚æœæ²¡æœ‰catalog_idï¼Œä½¿ç”¨ä¸­æ–‡åä½œä¸ºåå¤‡
                        chinese_name = ingredient.get('chinese_name', '')
                        if chinese_name:
                            grouped[standard_category].append(f"name_{chinese_name}")
                        logger.warning(f"å•é…æˆåˆ†ç¼ºå°‘catalog_id: {chinese_name}")
                else:
                    # å¤é…æˆåˆ†ï¼šä½¿ç”¨å¤é…åç§°ä½œä¸ºæ ‡è¯†ç¬¦ï¼Œæ·»åŠ å‰ç¼€ä¿æŒä¸€è‡´æ€§
                    chinese_name = ingredient.get('chinese_name', '')
                    if chinese_name:
                        grouped[standard_category].append(f"compound_{chinese_name}")

                logger.debug(
                    f"æˆåˆ†æ˜ å°„: {ingredient.get('chinese_name', 'æœªçŸ¥')} | åŸå§‹ç”¨é€”: '{raw_purpose}' | æ ‡å‡†åˆ†ç±»: '{standard_category}'")

            # åªè¿”å›æœ‰æˆåˆ†çš„åˆ†ç±»ï¼Œä¸åˆ›å»ºç©ºåˆ†ç±»
            result = {k: v for k, v in grouped.items() if v}  # è¿‡æ»¤æ‰ç©ºåˆ—è¡¨

            logger.info(f"åˆ†ç±»æ˜ å°„ç»“æœï¼ˆæˆåˆ†æ•°é‡ï¼‰: {[(k, len(v)) for k, v in result.items()]}")
            return result

        except Exception as e:
            logger.error(f"æˆåˆ†åˆ†ç±»å¤±è´¥: {e}")
            return {"å…¶ä»–": [f"catalog_{ing.get('catalog_id', '')}" if ing.get('catalog_id')
                             else f"name_{ing.get('chinese_name', '')}" for ing in ingredients]}

    def _get_common_ingredients(
            self,
            source_structure: Dict,
            target_structure: Dict
    ) -> List[str]:
        """è·å–å…±åŒæˆåˆ†"""
        # æå–æˆåˆ†åç§°é›†åˆ
        source_ingredients = set()
        target_ingredients = set()

        # å¤„ç†æºé…æ–¹æˆåˆ†
        for ing in source_structure.get('ingredients', []):
            if ing.get('type') == 'single':
                source_ingredients.add(ing['chinese_name'])
            elif ing.get('type') == 'compound':
                for comp in ing.get('components', []):
                    source_ingredients.add(comp['chinese_name'])
            else:
                # å…¼å®¹æ—§æ ¼å¼
                if 'chinese_name' in ing:
                    source_ingredients.add(ing['chinese_name'])

        # å¤„ç†ç›®æ ‡é…æ–¹æˆåˆ†
        for ing in target_structure.get('ingredients', []):
            if ing.get('type') == 'single':
                target_ingredients.add(ing['chinese_name'])
            elif ing.get('type') == 'compound':
                for comp in ing.get('components', []):
                    target_ingredients.add(comp['chinese_name'])
            else:
                # å…¼å®¹æ—§æ ¼å¼
                if 'chinese_name' in ing:
                    target_ingredients.add(ing['chinese_name'])

        return sorted(list(source_ingredients & target_ingredients))

    def batch_match_formulas(
            self,
            source_formula_ids: List[int],
            session,
            target_formulas: List[int] = None
    ) -> Dict[int, List[DualLibraryMatchResult]]:
        """æ‰¹é‡åŒ¹é…å¤šä¸ªé…æ–¹"""
        results = {}

        for source_id in source_formula_ids:
            try:
                match_results = self.match_formula_against_library(
                    source_id, session, target_formulas
                )
                results[source_id] = match_results
            except Exception as e:
                logger.error(f"æ‰¹é‡åŒ¹é…é…æ–¹ {source_id} å¤±è´¥: {e}")
                results[source_id] = []

        return results

    def get_matching_statistics(self, match_results: List[DualLibraryMatchResult]) -> Dict:
        """è·å–åŒ¹é…ç»Ÿè®¡ä¿¡æ¯"""
        if not match_results:
            return {}

        similarities = [r.similarity_score for r in match_results]

        return {
            "total_matches": len(match_results),
            "avg_similarity": np.mean(similarities),
            "max_similarity": np.max(similarities),
            "min_similarity": np.min(similarities),
            "std_similarity": np.std(similarities),
            "high_similarity_count": len([s for s in similarities if s >= 0.8]),
            "medium_similarity_count": len([s for s in similarities if 0.5 <= s < 0.8]),
            "low_similarity_count": len([s for s in similarities if s < 0.5])
        }


if __name__ == "__main__":
    print("ğŸ” åŒé…æ–¹åº“åŒ¹é…å¼•æ“")
    print("æ”¯æŒé…æ–¹åº“ä¸å¾…åŒ¹é…é…æ–¹åº“ä¹‹é—´çš„æ™ºèƒ½åŒ¹é…")
    print("å®ç°ä¸¤æ®µå¼ç›¸ä¼¼åº¦è®¡ç®—ï¼šæˆåˆ†ç»„æˆ + æˆåˆ†æ¯”ä¾‹")
